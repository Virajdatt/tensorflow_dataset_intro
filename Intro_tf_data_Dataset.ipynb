{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_tf_data_Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LYv_JIsXTQCxxwvtedF8IKgzAE8hhBh1#scrollTo=AKB-MYwPla8C)\n"
      ],
      "metadata": {
        "id": "AKB-MYwPla8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W_592w27pPjY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a tensorflow dataset using a list"
      ],
      "metadata": {
        "id": "4ImuDiKbpg-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_data = tf.data.Dataset.from_tensor_slices([1, 2, 3],)"
      ],
      "metadata": {
        "id": "EPzDIiBkpT5Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_data.element_spec # The type specification of an element of this dataset."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFJmvhOzpmsS",
        "outputId": "552acb9a-ccbd-4c09-fc7a-de73bdcecd3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(), dtype=tf.int32, name=None)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a tensorflow dataset using a numpy array"
      ],
      "metadata": {
        "id": "XoTZgglXqR7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_data = tf.data.Dataset.from_tensor_slices(np.array([\n",
        "                                                       [1, 2, 3],\n",
        "                                                       [4, 5, 6,],\n",
        "                                                       [7, 8, 9],\n",
        "                                                       ]\n",
        "                                            ))"
      ],
      "metadata": {
        "id": "k2oH1igkpnpU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_data.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbRWDVhFqmzy",
        "outputId": "97c85fff-8fb8-4cd5-d69f-2a0202df5c35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(3,), dtype=tf.int64, name=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A real use case example of creating a tensorflow dataset from numpy array"
      ],
      "metadata": {
        "id": "xdbDf23BsVqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data the mnist data\n",
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "# Read the images array's and the lables\n",
        "images, lables = train\n",
        "# Quick preprocess\n",
        "images = images/255.0\n",
        "\n",
        "# Create your dataset\n",
        "mnist_dataset = tf.data.Dataset.from_tensor_slices((images, lables))"
      ],
      "metadata": {
        "id": "fezCT722qofM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset.element_spec "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_cYskSyCfG",
        "outputId": "15613781-664a-4d74-da68-e8972b247cde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(28, 28), dtype=tf.float64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us look how the training images and the labels look within the tensorflow dataset. We can load the data out from a tensorflow dataset using the as_numpy_iterator() method which will let us access the data as numpy array. In our case it will let us inscpect the dataset"
      ],
      "metadata": {
        "id": "gwbXaxoNtHS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X is the first input array and y is the corresponding lable\n",
        "for X,y in mnist_dataset.as_numpy_iterator():\n",
        "  print(\"Shape of X, y\")\n",
        "  print(X.shape, y.shape)\n",
        "  print(type(X), \", This number is -->\", y) \n",
        "  break # to avoid iterating over all the training examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o8qoe80tAAL",
        "outputId": "561aec57-4437-43e8-8dbe-04edd19e7069"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X, y\n",
            "(28, 28) ()\n",
            "<class 'numpy.ndarray'> , This number is --> 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset2 = tf.data.Dataset.from_tensor_slices((images, lables, lables))"
      ],
      "metadata": {
        "id": "b-ErZsk7tCiu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset2.element_spec "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrs14BSux9lw",
        "outputId": "aee52acb-6ba5-4b95-ae85-4e2dd296c8bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(28, 28), dtype=tf.float64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zSEvOvSTyASq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important tensorflow methods"
      ],
      "metadata": {
        "id": "7ODa5vDg3DwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. range: Creates a Dataset of a step-separated range of values. signature start, stop, steps"
      ],
      "metadata": {
        "id": "MZwKvcB03I6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range_dataset = tf.data.Dataset.range(5)\n",
        "print(list(range_dataset.as_numpy_iterator()))\n",
        "\n",
        "range_stepped_dataset = tf.data.Dataset.range(1, 10, 3, output_type=tf.float32) # r\n",
        "print(list(range_stepped_dataset.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VswegLSr3Grz",
        "outputId": "2b3310f6-81c9-440a-d2ba-4fec95a278f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4]\n",
            "[1.0, 4.0, 7.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.map: lets you apply a function on each element of a tensor"
      ],
      "metadata": {
        "id": "CV-3U1qo5ubF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def div_by_4(x):\n",
        "  '''\n",
        "  A function that will help you divide each \n",
        "  tensor element by 4\n",
        "  '''\n",
        "  return x/4\n"
      ],
      "metadata": {
        "id": "Y35PWgPu3Uyd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. take: It creates a new dataset with the utmost count passed to it. Following is a quick demonstration of how the take method works. It also works with batched datasets and will demonstrate its behavior in the batch method."
      ],
      "metadata": {
        "id": "cgC6TX4ZHy4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range_dataset.map(div_by_4).as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZK25Ijp5gXS",
        "outputId": "44f65a28-f700-422d-e4af-2282ff9c8e91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.25, 0.5, 0.75, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in mnist_dataset.take(6).as_numpy_iterator():\n",
        "  print(X.shape, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4q58-i5mN7",
        "outputId": "a9ac7c3c-732c-49b9-c623-66b30441a173"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28) 5\n",
            "(28, 28) 0\n",
            "(28, 28) 4\n",
            "(28, 28) 1\n",
            "(28, 28) 9\n",
            "(28, 28) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. skip: It creates a Dataset that skips the count elements from the dataset. Let's see how this method works, in the example, below let's skip the first 3 elements from the mnist_dataset and take the next 3. If you have been following along in the tutorial we should see labels/images 1, 9, and 2 in order"
      ],
      "metadata": {
        "id": "9J7T6Y2VH4ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in mnist_dataset.skip(3).take(3).as_numpy_iterator():\n",
        "  print(X.shape, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Ql4pAD8QaG",
        "outputId": "7d719ec4-4b5a-478d-8c48-fda5ce0496bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28) 1\n",
            "(28, 28) 9\n",
            "(28, 28) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fist_six_images_taken = mnist_dataset.take(6)\n",
        "print('Lenght of the dataset',len(fist_six_images_taken))\n",
        "# Lenght of the dataset 6\n",
        "print(fist_six_images_taken.element_spec)\n",
        "# (TensorSpec(shape=(28, 28), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))\n",
        "\n",
        "for X,y in fist_six_images_taken.as_numpy_iterator():\n",
        "  print(X.shape, y)\n",
        "\n",
        "# (28, 28) 5\n",
        "# (28, 28) 0\n",
        "# (28, 28) 4\n",
        "# (28, 28) 1\n",
        "# (28, 28) 9\n",
        "# (28, 28) 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvFXBPRZ8qFJ",
        "outputId": "9b592488-f71e-4965-e04a-f30e9d78c64f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of the dataset 6\n",
            "(TensorSpec(shape=(28, 28), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))\n",
            "(28, 28) 5\n",
            "(28, 28) 0\n",
            "(28, 28) 4\n",
            "(28, 28) 1\n",
            "(28, 28) 9\n",
            "(28, 28) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.repeat: This method repeats the dataset values in order"
      ],
      "metadata": {
        "id": "LpA9hpq2ICCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset2 = tf.data.Dataset.range(3)\n",
        "repeated_dataset = dataset2.repeat(3)\n",
        "print(repeated_dataset.element_spec)\n",
        "print(list(repeated_dataset.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71DnafZq9ou6",
        "outputId": "7bdd7dea-3df2-4d29-bdfe-ba16aac97c46"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "[0, 1, 2, 0, 1, 2, 0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.shuffle: Randomly shuffles the elements of this dataset."
      ],
      "metadata": {
        "id": "mfcHcQbDLWeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset3 = tf.data.Dataset.range(3)\n",
        "print(list(dataset3.as_numpy_iterator()))\n",
        "print(list(dataset3.shuffle(3).as_numpy_iterator()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv_zGpAgIVkA",
        "outputId": "bb0f48db-565d-4141-d666-7d3119b3d683"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[0, 2, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [0, 1, 2]\n",
        "# [1, 2, 0]"
      ],
      "metadata": {
        "id": "tiqDL2t5Lm56"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. zip"
      ],
      "metadata": {
        "id": "bgwckvPEMT36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array([[1, 2, 3],\n",
        "                    [4, 5, 6],\n",
        "                    [7, 8, 9]])\n",
        "labels = np.array([0, 0, 1])\n",
        "d_ds = tf.data.Dataset.from_tensor_slices(np_array)\n",
        "lab_tf = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "# Zipping 2 tf datasets\n",
        "zipped_dataset = tf.data.Dataset.zip((d_ds, lab_tf))\n",
        "\n",
        "print('Array   , Label')\n",
        "for x,y in zipped_dataset.as_numpy_iterator():\n",
        "    \n",
        "    print(x, ',' ,y)\n",
        "# Array   , Label\n",
        "# [1 2 3] , 0\n",
        "# [4 5 6] , 0\n",
        "# [7 8 9] , 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL6fX6U-MW_K",
        "outputId": "397aabbf-d5b1-4fc9-f88c-72e5310734ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array   , Label\n",
            "[1 2 3] , 0\n",
            "[4 5 6] , 0\n",
            "[7 8 9] , 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. batch\n",
        "This function is used to combine consecutive of elements a dataset into batches based on the batch_size specified."
      ],
      "metadata": {
        "id": "pW3x8QCrNqV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ds = zipped_dataset.batch(2)\n",
        "\n",
        "print('batched dataset, lables')\n",
        "for i in batched_ds:\n",
        "  print(i[0].shape, '        ,  ',i[1].shape)\n",
        "print()\n",
        "\n",
        "print('Elements of the batched dataset')\n",
        "for X,y in batched_ds.as_numpy_iterator():\n",
        "  print('X= ', X)\n",
        "  print('y= ',y)\n",
        "# batched dataset, lables\n",
        "# (2, 3)         ,   (2,)\n",
        "# (1, 3)         ,   (1,)\n",
        "\n",
        "# Elements of the batched dataset\n",
        "# X=  [[1 2 3]\n",
        "#     [4 5 6]]\n",
        "\n",
        "# y=  [0 0]\n",
        "\n",
        "# X=  [[7 8 9]]\n",
        "# y=  [1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biJ2ook_Mdps",
        "outputId": "3b662b85-f30c-4560-8f27-29627d091e26"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batched dataset, lables\n",
            "(2, 3)         ,   (2,)\n",
            "(1, 3)         ,   (1,)\n",
            "\n",
            "Elements of the batched dataset\n",
            "X=  [[1 2 3]\n",
            " [4 5 6]]\n",
            "y=  [0 0]\n",
            "X=  [[7 8 9]]\n",
            "y=  [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ds = zipped_dataset.batch(2, drop_remainder=True)\n",
        "\n",
        "print('batched dataset, lables')\n",
        "for i in batched_ds:\n",
        "  print(i[0].shape, i[1].shape)\n",
        "print()\n",
        "\n",
        "print('Elements of the batched dataset')\n",
        "for X,y in batched_ds.as_numpy_iterator():\n",
        "  print('X= ', X)\n",
        "  print('y= ',y)\n",
        "# batched dataset, lables\n",
        "# (2, 3) (2,)\n",
        "\n",
        "# Elements of the batched dataset\n",
        "# X=  [[1 2 3]\n",
        "#     [4 5 6]]\n",
        "# y=  [0 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru177GskOK8n",
        "outputId": "92fc2f34-05b3-4767-9524-8f8a915cad42"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batched dataset, lables\n",
            "(2, 3) (2,)\n",
            "\n",
            "Elements of the batched dataset\n",
            "X=  [[1 2 3]\n",
            " [4 5 6]]\n",
            "y=  [0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. window"
      ],
      "metadata": {
        "id": "8j1mSmOZRbDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.range(10)\n",
        "print('Orginal data', list(data.as_numpy_iterator()))\n",
        "#  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "windowed_data = data.window(5, shift=1, drop_remainder=True)\n",
        "for window_data in windowed_data:\n",
        "    for val in window_data:\n",
        "        print(val.numpy(), end=\" \")\n",
        "    print()\n",
        "# Orginal data [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "# 0 1 2 3 4 \n",
        "# 1 2 3 4 5 \n",
        "# 2 3 4 5 6 \n",
        "# 3 4 5 6 7 \n",
        "# 4 5 6 7 8 \n",
        "# 5 6 7 8 9 \n",
        "print('-------')\n",
        "\n",
        "# with shift = 2\n",
        "windowed_data = data.window(5, shift=2, drop_remainder=True)\n",
        "for window_data in windowed_data:\n",
        "    for val in window_data:\n",
        "        print(val.numpy(), end=\" \")\n",
        "    print()\n",
        "\n",
        "# 0 1 2 3 4 \n",
        "# 2 3 4 5 6 \n",
        "# 4 5 6 7 8 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iguVzGbwOW6v",
        "outputId": "658d05cb-95fd-44d7-de1b-c2a66325234b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginal data [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "-------\n",
            "0 1 2 3 4 \n",
            "2 3 4 5 6 \n",
            "4 5 6 7 8 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method Chaining in tensorflow for your pipeline"
      ],
      "metadata": {
        "id": "H8K_CV4tU3ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndataset = tf.data.Dataset.range(10)\n",
        "ndataset = ndataset.window(5, shift=1, drop_remainder=True)\n",
        "ndataset = ndataset.flat_map(lambda window: window.batch(5))\n",
        "ndataset = ndataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "ndataset = ndataset.shuffle(buffer_size=10)\n",
        "ndataset = ndataset.batch(3).prefetch(1)\n",
        "\n",
        "\n",
        "for x, y in ndataset:\n",
        "    print(\"x = \", list(x.numpy()))\n",
        "    print(\"y = \", list(y.numpy()))\n",
        "\n",
        "# x =  [array([4, 5, 6, 7]), array([5, 6, 7, 8]), array([3, 4, 5, 6])]\n",
        "# y =  [array([8]), array([9]), array([7])]\n",
        "# x =  [array([0, 1, 2, 3]), array([2, 3, 4, 5]), array([1, 2, 3, 4])]\n",
        "# y =  [array([4]), array([6]), array([5])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RVqdDtlReiO",
        "outputId": "98af2b14-e0f4-40f1-ab1a-cbf6fa91d4d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [array([3, 4, 5, 6]), array([5, 6, 7, 8]), array([0, 1, 2, 3])]\n",
            "y =  [array([7]), array([9]), array([4])]\n",
            "x =  [array([4, 5, 6, 7]), array([1, 2, 3, 4]), array([2, 3, 4, 5])]\n",
            "y =  [array([8]), array([5]), array([6])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A much better way of chaining them together"
      ],
      "metadata": {
        "id": "xusobb2ZY6Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndataset2 = tf.data.Dataset.range(10)\n",
        "\n",
        "ndataset2= ndataset2.window(5, shift=1, drop_remainder=True) \\\n",
        "                    .flat_map(lambda window: window.batch(5)) \\\n",
        "                    .map(lambda window2: (window2[:-1], window2[-1:])) \\\n",
        "                    .shuffle(buffer_size=10) \\\n",
        "                    .batch(3).prefetch(1)\n",
        "\n",
        "for x, y in ndataset2:\n",
        "    print(\"x = \", list(x.numpy()))\n",
        "    print(\"y = \", list(y.numpy()))\n",
        "\n",
        "# x =  [array([1, 2, 3, 4]), array([2, 3, 4, 5]), array([5, 6, 7, 8])]\n",
        "# y =  [array([5]), array([6]), array([9])]\n",
        "# x =  [array([0, 1, 2, 3]), array([4, 5, 6, 7]), array([3, 4, 5, 6])]\n",
        "# y =  [array([4]), array([8]), array([7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjFEqVofTQ9p",
        "outputId": "9dfaaded-c162-4ffc-e086-6b2f72b9c11e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [array([4, 5, 6, 7]), array([3, 4, 5, 6]), array([2, 3, 4, 5])]\n",
            "y =  [array([8]), array([7]), array([6])]\n",
            "x =  [array([0, 1, 2, 3]), array([1, 2, 3, 4]), array([5, 6, 7, 8])]\n",
            "y =  [array([4]), array([5]), array([9])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My preffered way: \n",
        "### Chain the transformations togther using a function (makes the code much more readable, easier to understand and reusable in most cases)"
      ],
      "metadata": {
        "id": "UpyXVVe_ZUj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_window_dataset(ds, window_size=5, shift=1, batch_size=3):\n",
        "  '''\n",
        "  This function helps in creating a windowed dataset.\n",
        "  The window size is set to 5 which shifts the element by 1\n",
        "  and returns a tf.dataset of batch size 3\n",
        "  '''\n",
        "  return ds.window(window_size, shift=shift, drop_remainder=True) \\\n",
        "                    .flat_map(lambda window: window.batch(5)) \\\n",
        "                    .map(lambda window2: (window2[:-1], window2[-1:])) \\\n",
        "                    .shuffle(buffer_size=10) \\\n",
        "                    .batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "rWDKqn0ZUB6Q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nds3 = tf.data.Dataset.range(10, 20)\n",
        "nds3 = nds3.apply(make_window_dataset)\n",
        "for x, y in nds3:\n",
        "    print(\"x = \", list(x.numpy()))\n",
        "    print(\"y = \", list(y.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LhAzH7uXvLP",
        "outputId": "2da8a8c6-1d99-4f92-d4f0-b5c4fa8ce0c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [array([13, 14, 15, 16]), array([11, 12, 13, 14]), array([12, 13, 14, 15])]\n",
            "y =  [array([17]), array([15]), array([16])]\n",
            "x =  [array([15, 16, 17, 18]), array([10, 11, 12, 13]), array([14, 15, 16, 17])]\n",
            "y =  [array([19]), array([14]), array([18])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f4qw_UvxX9ni"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}